---
title: コンピュータを構成する2つの最適化
---

コンピュータサイエンスは、人類の築いてきた工学の最先端であり最も多くの人が関わった構築物であると言っても過言でないでしょう。人間は抽象化と階層化を繰り返すことで、コンピュータは発達してきました。コンピュータの階層を見ていきましょう。

## コンピュータの階層

![computer science](./computer-sicence.png)
このようにコンピュータは、物理法則、論理ゲート、回路、ALU/メモリ、コンピュータアーキテクチャ、機械語、アセンブラ、バーチャルマシン、コンパイラ、OS、プログラミング言語、アプリケーション、データサイエンス/機械学習の層で構成されています。

最も下と最も上のピンク色の層でである物理法則、デーサイエンス/機械学習の分野では、連続最適化が行われています。
回路からプログラミング言語/アプリケーション層までは離散最適化が行われています。

連続最適化とは、目的関数の最小値を得ることのできる連続値のパラメータを見つけることです。
離散最適化とは、目的関数の最小値を得ることのできる離散値のパラメータの組み合わせを見つけることです。

このように、コンピュータサイエンスの重要な部分は離散最適化によって成り立っています。
離散最適化を構成するデータ構造とアルゴリズムは、コンピュータサイエンスを学ぶ上で重要な分野になります。
それを踏まえると、GAFAは離散最適化のスペシャリスト集団であると言ってよいでしょう。
データ構造とアルゴリズムのテストはGAFAの入社試験で重要視されています。

近年、データサイエンスやAIが話題になっています。データサイエンスやAIは連続最適化の分野にあたります。bitを連続値の近似として扱っています。深層学習では主に1階の微分情報による連続最適化が行われています。
一方で、深層学習の発展には動的計画法という離散最適化アルゴリズムが大きく貢献しています。
深層学習とは、ホワイトボックスな抽象化と階層化に相当する操作を、深層学習で暗黙的に実現します。
深層学習の領域では自動言語処理や画像認識などの分野で大きな成果が出ています。


